from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage
import json

# é…ç½® Moonshot å¤§æ¨¡å‹
llm = ChatOpenAI(
    model_name="moonshot-v1-8k",
    openai_api_base="https://api.moonshot.cn/v1",
    openai_api_key="sk-iw52Xktj1kqdKIICxd5tX6WQBYtW94yznBRy37RodQET03Cj",
    temperature=0.7
)

def manual_crewai_simulation():
    """æ‰‹åŠ¨æ¨¡æ‹Ÿ crewai çš„å·¥ä½œæµç¨‹"""
    
    # æ¨¡æ‹Ÿ Agent 1: æ•°æ®åˆ†æå¸ˆ
    print("ğŸ¤– Agent 1: æ•°æ®åˆ†æå¸ˆå¼€å§‹å·¥ä½œ...")
    
    # æ„å»ºæ•°æ®åˆ†æå¸ˆçš„ä»»åŠ¡æç¤º
    analyst_prompt = """
    ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„æ•°æ®åˆ†æå¸ˆã€‚è¯·åˆ†æä»¥ä¸‹åº“å­˜æ•°æ®å¹¶è¯†åˆ«ä½åº“å­˜å•†å“ã€‚

    æ•°æ®æ–‡ä»¶ä¿¡æ¯ï¼š
    - é”€å”®è®°å½•: sales_records.csv (3000è¡Œæ•°æ®)
    - å•†å“ä¿¡æ¯: products.csv (100ä¸ªå•†å“)
    - åº“å­˜æ•°æ®: inventory.csv (100ä¸ªå•†å“åº“å­˜)

    è¯·è¿”å›JSONæ ¼å¼çš„åˆ†æç»“æœï¼Œç»“æ„å¦‚ä¸‹ï¼š
    {
        "low_stock_products": [
            {
                "product_id": "P001",
                "name": "å•†å“åç§°",
                "current_stock": 50,
                "safety_stock": 100,
                "days_of_inventory": 5.2,
                "out_of_stock_risk": 50.0
            }
        ],
        "overall_health": "ä¸ä½³",
        "key_findings": "å‘ç°10ä¸ªå•†å“ä½äºå®‰å…¨åº“å­˜æ°´å¹³ï¼Œå…¶ä¸­3ä¸ªå•†å“ç¼ºè´§é£é™©é«˜äº70%"
    }
    """
    
    try:
        # æ‰‹åŠ¨è°ƒç”¨ LLMï¼Œåªä¼ é€’å¿…è¦çš„å‚æ•°
        messages = [
            SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°æ®åˆ†æå¸ˆï¼Œæ“…é•¿åˆ†æåº“å­˜æ•°æ®ã€‚"),
            HumanMessage(content=analyst_prompt)
        ]
        
        response1 = llm.invoke(messages)
        print("âœ… Agent 1 åˆ†æå®Œæˆ")
        print("åˆ†æç»“æœ:", response1.content)
        
        # æ¨¡æ‹Ÿ Agent 2: ç­–ç•¥é¡¾é—®
        print("\nğŸ¤– Agent 2: ç­–ç•¥é¡¾é—®å¼€å§‹å·¥ä½œ...")
        
        # ä½¿ç”¨ Agent 1 çš„ç»“æœä½œä¸ºè¾“å…¥
        strategy_prompt = f"""
        ä½ æ˜¯ä¸€ä½èµ„æ·±çš„åº“å­˜ç­–ç•¥é¡¾é—®ã€‚æ ¹æ®æ•°æ®åˆ†æå¸ˆçš„åˆ†æç»“æœï¼š
        
        {response1.content}
        
        è¯·ä¸ºä½åº“å­˜å•†å“åˆ¶å®šå…·ä½“çš„è¡¥è´§å»ºè®®å’Œä¿ƒé”€ç­–ç•¥ã€‚
        
        è¯·è¿”å›JSONæ ¼å¼çš„ç­–ç•¥å»ºè®®ï¼Œç»“æ„å¦‚ä¸‹ï¼š
        {{
            "replenishment_strategies": [
                {{
                    "product_id": "P001",
                    "replenishment_amount": 200,
                    "timeline": "ç´§æ€¥è¡¥è´§ï¼ˆ48å°æ—¶å†…ï¼‰",
                    "reason": "é«˜ç¼ºè´§é£é™©ä¸”é”€å”®è¶‹åŠ¿ä¸Šå‡"
                }}
            ],
            "promotion_strategies": [
                {{
                    "product_id": "P045",
                    "promotion_method": "é™æ—¶æŠ˜æ‰£",
                    "discount_rate": 15,
                    "duration": "2å‘¨"
                }}
            ],
            "overall_recommendations": "å»ºè®®ä¼˜åŒ–å®‰å…¨åº“å­˜è®¡ç®—å…¬å¼å¹¶å»ºç«‹è‡ªåŠ¨è¡¥è´§ç³»ç»Ÿ"
        }}
        """
        
        messages2 = [
            SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åº“å­˜ç­–ç•¥é¡¾é—®ï¼Œæ“…é•¿åˆ¶å®šè¡¥è´§å’Œä¿ƒé”€ç­–ç•¥ã€‚"),
            HumanMessage(content=strategy_prompt)
        ]
        
        response2 = llm.invoke(messages2)
        print("âœ… Agent 2 ç­–ç•¥åˆ¶å®šå®Œæˆ")
        print("ç­–ç•¥å»ºè®®:", response2.content)
        
        # æ¨¡æ‹Ÿ Agent 3: æŠ¥å‘Šç”Ÿæˆå™¨
        print("\nğŸ¤– Agent 3: æŠ¥å‘Šç”Ÿæˆå™¨å¼€å§‹å·¥ä½œ...")
        
        report_prompt = f"""
        ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æŠ¥å‘Šæ’°å†™ä¸“å®¶ã€‚æ ¹æ®ä»¥ä¸‹åˆ†æç»“æœå’Œç­–ç•¥å»ºè®®ï¼Œæ’°å†™ä¸€ä»½å…¨é¢çš„åº“å­˜ç®¡ç†æŠ¥å‘Šï¼š

        æ•°æ®åˆ†æç»“æœï¼š
        {response1.content}

        ç­–ç•¥å»ºè®®ï¼š
        {response2.content}

        è¯·ç”Ÿæˆä¸€ä»½å®Œæ•´çš„Markdownæ ¼å¼åº“å­˜ç®¡ç†æŠ¥å‘Šï¼ŒåŒ…å«ï¼š
        1. æ‰§è¡Œæ‘˜è¦
        2. è¯¦ç»†åº“å­˜åˆ†æ
        3. å…·ä½“è¡¥è´§å’Œä¿ƒé”€ç­–ç•¥
        4. å®æ–½è®¡åˆ’å’Œæ—¶é—´è¡¨
        5. é¢„æœŸæ•ˆæœå’ŒROIåˆ†æ
        """
        
        messages3 = [
            SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ¥å‘Šæ’°å†™ä¸“å®¶ï¼Œæ“…é•¿å°†å¤æ‚ä¿¡æ¯æ•´ç†æˆæ¸…æ™°çš„æŠ¥å‘Šã€‚"),
            HumanMessage(content=report_prompt)
        ]
        
        response3 = llm.invoke(messages3)
        print("âœ… Agent 3 æŠ¥å‘Šç”Ÿæˆå®Œæˆ")
        
        # ä¿å­˜æœ€ç»ˆæŠ¥å‘Š
        with open('manual_inventory_report.md', 'w', encoding='utf-8') as f:
            f.write(response3.content)
        
        print("\nğŸ‰ æ‰‹åŠ¨å·¥ä½œæµæ‰§è¡ŒæˆåŠŸï¼")
        print("ğŸ“„ æŠ¥å‘Šå·²ä¿å­˜åˆ°: manual_inventory_report.md")
        print("\n" + "="*50)
        print("æœ€ç»ˆæŠ¥å‘Šé¢„è§ˆ:")
        print("="*50)
        print(response3.content[:500] + "..." if len(response3.content) > 500 else response3.content)
        
        return True
        
    except Exception as e:
        print(f"âŒ æ‰‹åŠ¨å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹æ‰‹åŠ¨æ¨¡æ‹Ÿ CrewAI å·¥ä½œæµ...")
    print("="*50)
    manual_crewai_simulation() 